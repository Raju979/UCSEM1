{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "893c08f1-dfd8-4bf7-ae14-445ab998089c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-07 22:54:30.527555: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape: (64, 64, 64, 3) (64, 1)\n",
      "Models created successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-07 22:54:35.310447: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import pathlib\n",
    "\n",
    "# Defining the image and attributes paths\n",
    "dataset_path = \"img_align_celeba\"  \n",
    "attr_path = \"list_attr_celeba.csv\" \n",
    "\n",
    "# Loading the attributes\n",
    "df = pd.read_csv(attr_path)\n",
    "df.set_index(\"image_id\", inplace=True)\n",
    "\n",
    "# Selecting the desired attributes For example: Smiling\n",
    "selected_attr = [\"Smiling\"]\n",
    "labels = df[selected_attr].replace(-1, 0).astype(np.float32) \n",
    "\n",
    "# Loading the dataset\n",
    "def load_image(image_path, label):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, (64, 64))  # Resizing to the required dimensions\n",
    "    img = img / 255.0  # Normalize to [0, 1]\n",
    "    return img, label\n",
    "\n",
    "# Creating the list of image paths\n",
    "image_paths = [os.path.join(dataset_path, img) for img in labels.index]\n",
    "labels = labels.values  # Converting to the numpy array\n",
    "\n",
    "# Converting to the TensorFlow dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
    "dataset = dataset.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "dataset = dataset.batch(64).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Test dataset\n",
    "for images, labels in dataset.take(1):\n",
    "    print(\"Batch shape:\", images.shape, labels.shape)\n",
    "\n",
    "# Defining the Generator\n",
    "def build_generator(latent_dim, num_classes):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(8 * 8 * 256, activation=\"relu\", input_dim=latent_dim + num_classes),\n",
    "        tf.keras.layers.Reshape((8, 8, 256)),\n",
    "        tf.keras.layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\", activation=\"relu\"),\n",
    "        tf.keras.layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding=\"same\", activation=\"relu\"),\n",
    "        tf.keras.layers.Conv2DTranspose(3, kernel_size=4, strides=2, padding=\"same\", activation=\"sigmoid\")\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Defining the Discriminator\n",
    "def build_discriminator():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\", activation=\"relu\", input_shape=(64, 64, 3)),\n",
    "        tf.keras.layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\", activation=\"relu\"),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Initializing the models\n",
    "latent_dim = 100\n",
    "num_classes = 1  # Binary classification that is: Smiling or Not\n",
    "generator = build_generator(latent_dim, num_classes)\n",
    "discriminator = build_discriminator()\n",
    "\n",
    "print(\"Models created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57eb19f4-94ae-4e9f-a6ca-baa4c9be3d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-07 23:04:34.407321: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Gen Loss: 1.0727, Disc Loss: 0.2762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-07 23:06:19.460043: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Gen Loss: 1.1434, Disc Loss: 0.2611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-07 23:08:05.685653: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Gen Loss: 7.5090, Disc Loss: 0.2956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-07 23:09:51.960405: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Gen Loss: 2.4496, Disc Loss: 0.3453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-07 23:11:37.252762: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Gen Loss: 8.8319, Disc Loss: 0.4352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-07 23:13:22.756114: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Gen Loss: 3.1943, Disc Loss: 0.3617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-07 23:15:08.430669: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Gen Loss: 3.2950, Disc Loss: 0.0387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-07 23:16:54.466823: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Gen Loss: 1.8483, Disc Loss: 0.2227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-07 23:18:38.973022: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Gen Loss: 3.0351, Disc Loss: 0.2042\n",
      "Epoch 10, Gen Loss: 2.1938, Disc Loss: 0.2058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-07 23:20:23.316812: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "# Defining constants\n",
    "BATCH_SIZE = 32\n",
    "NOISE_DIM = 100\n",
    "NUM_CLASSES = 1 \n",
    "TOTAL_INPUT_DIM = NOISE_DIM + NUM_CLASSES  \n",
    "\n",
    "# Generator Model\n",
    "def build_generator():\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(256, activation=\"relu\", input_shape=(TOTAL_INPUT_DIM,)),\n",
    "        layers.Dense(512, activation=\"relu\"),\n",
    "        layers.Dense(1024, activation=\"relu\"),\n",
    "        layers.Dense(32 * 32 * 3, activation=\"tanh\"),\n",
    "        layers.Reshape((32, 32, 3))\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Discriminator Model\n",
    "def build_discriminator():\n",
    "    model = keras.Sequential([\n",
    "        layers.Flatten(input_shape=(32, 32, 3)),\n",
    "        layers.Dense(512, activation=\"relu\"),\n",
    "        layers.Dense(256, activation=\"relu\"),\n",
    "        layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Creating the models\n",
    "generator = build_generator()\n",
    "discriminator = build_discriminator()\n",
    "\n",
    "# Loss function and the Optimizers\n",
    "cross_entropy = keras.losses.BinaryCrossentropy()\n",
    "\n",
    "generator_optimizer = keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "discriminator_optimizer = keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "# Training step function\n",
    "@tf.function\n",
    "def train_step(real_images, labels):\n",
    "    batch_size = tf.shape(real_images)[0]\n",
    "\n",
    "    # Generating the random noise\n",
    "    noise = tf.random.normal([batch_size, NOISE_DIM])\n",
    "\n",
    "    # Converting the labels to one-hot encoding and reshape\n",
    "    labels = tf.one_hot(labels, depth=NUM_CLASSES)\n",
    "    labels = tf.reshape(labels, (batch_size, NUM_CLASSES))\n",
    "\n",
    "    # Concatenating the noise and labels correctly\n",
    "    noise_and_labels = tf.concat([noise, labels], axis=1)\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        fake_images = generator(noise_and_labels, training=True)\n",
    "\n",
    "        real_output = discriminator(real_images, training=True)\n",
    "        fake_output = discriminator(fake_images, training=True)\n",
    "\n",
    "        # Calculating the loss\n",
    "        gen_loss = cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "        disc_loss = (cross_entropy(tf.ones_like(real_output), real_output) +\n",
    "                     cross_entropy(tf.zeros_like(fake_output), fake_output)) / 2\n",
    "\n",
    "    # Computing the gradients\n",
    "    gen_gradients = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    disc_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    # Applying the gradients\n",
    "    generator_optimizer.apply_gradients(zip(gen_gradients, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(disc_gradients, discriminator.trainable_variables))\n",
    "\n",
    "    return gen_loss, disc_loss\n",
    "\n",
    "# Training function\n",
    "def train(dataset, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        for images, labels in dataset:\n",
    "            gen_loss, disc_loss = train_step(images, labels)\n",
    "        print(f\"Epoch {epoch+1}, Gen Loss: {gen_loss:.4f}, Disc Loss: {disc_loss:.4f}\")\n",
    "\n",
    "# I am taking an example for a dummy dataset\n",
    "(x_train, y_train), (_, _) = keras.datasets.cifar10.load_data()\n",
    "x_train = (x_train.astype(\"float32\") - 127.5) / 127.5  # Normalizing to [-1, 1]\n",
    "y_train = y_train.flatten() \n",
    "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(BATCH_SIZE)\n",
    "\n",
    "# Run the training\n",
    "train(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75e150a-67ca-46d2-8fd2-526b4109230c",
   "metadata": {},
   "source": [
    "The GAN training ran smoothly for over 10 epochs. The generator loss started at about 1.07, while the discriminator loss was low at 0.27, which implies that the discriminator was effectively discriminating between real and fake images. In further training, generator loss showed some fluctuations: it reached highs of 7.50 and 8.83 in certain epochs, reflecting moments when the generator struggled to generate realistic samples. It continued relatively stable, but with some variability that could indicate a dynamic competition between the two networks. It is also worth noting that by epoch 7, the discriminator loss had fallen significantly to 0.0387, which may indicate overpowering against the generator. However, in the further epochs, the generator losses have stabilized, and the discriminator loss remained at a moderate value, allowing it to learn the model effectively. It would also be achieved in the results by fine-tuning these hyperparameters, dataset size, or architectural changes that achieve balance and realism."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
