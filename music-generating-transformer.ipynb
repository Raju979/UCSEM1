{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76751e97-ae7c-413e-8447-206cba128e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file created: bach_cello_suites.mid\n",
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - duration_output_accuracy: 0.0000e+00 - loss: 4.6195 - note_output_accuracy: 0.3333\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - duration_output_accuracy: 0.6667 - loss: 2.0965 - note_output_accuracy: 0.6667\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - duration_output_accuracy: 1.0000 - loss: 1.2724 - note_output_accuracy: 0.6667\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - duration_output_accuracy: 1.0000 - loss: 0.7851 - note_output_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - duration_output_accuracy: 1.0000 - loss: 0.6966 - note_output_accuracy: 0.6667\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - duration_output_accuracy: 1.0000 - loss: 0.4965 - note_output_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - duration_output_accuracy: 1.0000 - loss: 0.3031 - note_output_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - duration_output_accuracy: 1.0000 - loss: 0.2678 - note_output_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - duration_output_accuracy: 1.0000 - loss: 0.2327 - note_output_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - duration_output_accuracy: 1.0000 - loss: 0.1569 - note_output_accuracy: 1.0000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Generated Music: [(60, 1.5), (71, 1.0), (71, 1.0), (69, 1.5), (69, 1.5), (69, 1.5), (69, 1.5), (69, 1.5), (69, 1.5), (69, 1.5), (69, 1.5), (69, 1.5), (69, 1.5), (69, 1.5), (69, 1.5), (69, 1.5), (69, 1.5), (69, 1.5), (69, 1.5), (69, 1.5), (69, 1.5)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pretty_midi\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Starting with generating a MIDI file Programmatically\n",
    "def create_midi_file(filename=\"bach_cello_suites.mid\"):\n",
    "    midi = pretty_midi.PrettyMIDI()\n",
    "    instrument = pretty_midi.Instrument(program=42) \n",
    "    \n",
    "    notes = [  # Random Cello Notes (Pitch, Duration)\n",
    "        (60, 1.0), (62, 0.5), (64, 1.5), (65, 1.0), (67, 0.5), (69, 1.5), (71, 1.0), (72, 0.5)\n",
    "    ]\n",
    "    \n",
    "    for pitch, duration in notes:\n",
    "        note = pretty_midi.Note(velocity=100, pitch=pitch, \n",
    "                                start=midi.get_end_time(), end=midi.get_end_time() + duration)\n",
    "        instrument.notes.append(note)\n",
    "    \n",
    "    midi.instruments.append(instrument)\n",
    "    midi.write(filename)\n",
    "    print(f\"MIDI file created: {filename}\")\n",
    "    \n",
    "create_midi_file()\n",
    "\n",
    "# Extracting the Notes and Durations from MIDI\n",
    "def midi_to_notes(midi_path):\n",
    "    pm = pretty_midi.PrettyMIDI(midi_path)\n",
    "    notes = []\n",
    "    \n",
    "    for instrument in pm.instruments:\n",
    "        for note in instrument.notes:\n",
    "            pitch = note.pitch  # Note (e.g., C4 = 60)\n",
    "            duration = note.end - note.start  # Duration\n",
    "            notes.append((pitch, duration))\n",
    "    \n",
    "    return notes\n",
    "\n",
    "midi_file = \"bach_cello_suites.mid\"\n",
    "notes_data = midi_to_notes(midi_file)\n",
    "\n",
    "# Tokenizing the Notes and Durations\n",
    "unique_notes = sorted(set(n[0] for n in notes_data))\n",
    "unique_durations = sorted(set(n[1] for n in notes_data))\n",
    "\n",
    "note_to_int = {note: i for i, note in enumerate(unique_notes)}\n",
    "duration_to_int = {duration: i for i, duration in enumerate(unique_durations)}\n",
    "\n",
    "int_to_note = {i: note for note, i in note_to_int.items()}\n",
    "int_to_duration = {i: duration for duration, i in duration_to_int.items()}\n",
    "\n",
    "tokenized_data = [(note_to_int[n], duration_to_int[d]) for n, d in notes_data]\n",
    "\n",
    "# Converting to sequence format\n",
    "seq_len = 5  # Sequence Length\n",
    "input_notes = []\n",
    "input_durations = []\n",
    "output_notes = []\n",
    "output_durations = []\n",
    "\n",
    "for i in range(len(tokenized_data) - seq_len):\n",
    "    seq = tokenized_data[i:i + seq_len]\n",
    "    input_notes.append([n[0] for n in seq])\n",
    "    input_durations.append([n[1] for n in seq])\n",
    "    output_notes.append(tokenized_data[i + seq_len][0])\n",
    "    output_durations.append(tokenized_data[i + seq_len][1])\n",
    "\n",
    "input_notes = np.array(input_notes)\n",
    "input_durations = np.array(input_durations)\n",
    "output_notes = np.array(output_notes)\n",
    "output_durations = np.array(output_durations)\n",
    "\n",
    "# Building the Transformer Model\n",
    "def build_transformer(note_vocab_size, duration_vocab_size, seq_len, embed_dim=128, num_heads=4, ff_dim=256):\n",
    "    note_inputs = tf.keras.layers.Input(shape=(seq_len,))\n",
    "    duration_inputs = tf.keras.layers.Input(shape=(seq_len,))\n",
    "    \n",
    "    note_embedding = tf.keras.layers.Embedding(note_vocab_size, embed_dim)(note_inputs)\n",
    "    duration_embedding = tf.keras.layers.Embedding(duration_vocab_size, embed_dim)(duration_inputs)\n",
    "    \n",
    "    x = tf.keras.layers.Concatenate()([note_embedding, duration_embedding])\n",
    "    \n",
    "    attn_output = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(x, x)\n",
    "    x = tf.keras.layers.Add()([x, attn_output])\n",
    "    x = tf.keras.layers.LayerNormalization()(x)\n",
    "    \n",
    "    x = tf.keras.layers.Dense(ff_dim, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dense(embed_dim)(x)\n",
    "    x = tf.keras.layers.LayerNormalization()(x)\n",
    "    \n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "    note_output = tf.keras.layers.Dense(note_vocab_size, activation=\"softmax\", name=\"note_output\")(x)\n",
    "    duration_output = tf.keras.layers.Dense(duration_vocab_size, activation=\"softmax\", name=\"duration_output\")(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[note_inputs, duration_inputs], outputs=[note_output, duration_output])\n",
    "    model.compile(\n",
    "    loss=[\"sparse_categorical_crossentropy\", \"sparse_categorical_crossentropy\"],\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\", \"accuracy\"]\n",
    ")\n",
    "\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_transformer(len(note_to_int), len(duration_to_int), seq_len)\n",
    "model.fit([input_notes, input_durations], [output_notes, output_durations], epochs=10, batch_size=16)\n",
    "\n",
    "# Generating the new music\n",
    "def generate_music(model, start_note, start_duration, length=20):\n",
    "    note_sequence = [start_note]\n",
    "    duration_sequence = [start_duration]\n",
    "    \n",
    "    for _ in range(length):\n",
    "        input_notes = pad_sequences([note_sequence], maxlen=seq_len, padding=\"pre\")\n",
    "        input_durations = pad_sequences([duration_sequence], maxlen=seq_len, padding=\"pre\")\n",
    "        \n",
    "        pred_note, pred_duration = model.predict([input_notes, input_durations])\n",
    "        pred_note = np.argmax(pred_note)\n",
    "        pred_duration = np.argmax(pred_duration)\n",
    "        \n",
    "        note_sequence.append(pred_note)\n",
    "        duration_sequence.append(pred_duration)\n",
    "    \n",
    "    return [(int_to_note[n], int_to_duration[d]) for n, d in zip(note_sequence, duration_sequence)]\n",
    "\n",
    "start_note = random.choice(list(note_to_int.values()))\n",
    "start_duration = random.choice(list(duration_to_int.values()))\n",
    "\n",
    "generated_music = generate_music(model, start_note, start_duration)\n",
    "print(\"Generated Music:\", generated_music)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8077c590-cbff-46cf-935a-62fe4f3136e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
