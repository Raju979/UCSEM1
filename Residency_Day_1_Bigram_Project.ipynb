{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893b4d13-7fca-4e4b-824a-565ffb070d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residency Day 1: Bigram Project\n",
    "# imports\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "101e42f9-30df-4859-bdc5-ba23bc88d414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KBR said Friday the global economic downturn so far has\n",
      "had\n",
      "little effect on its business but warned some projects on its books\n",
      "could be in jeopardy if the headwinds persist into next year.\n",
      "\n",
      "\"With the economic outlook remaining uncertain, it is possible\n",
      "that\n",
      "customers may cancel or delay projects that are under way,\" said\n",
      "William\n",
      "Utt, chief executive of the Houston-based engineering and\n",
      "construction\n",
      "giant and government contractor.\n"
     ]
    }
   ],
   "source": [
    "# Loading the given txt file as data.\n",
    "with open(\"Nyt.200811.txt\",\"r\",encoding = \"utf-8\") as nyt: # Reading the file and encoding using utf-8.\n",
    "    fullTexts = nyt.read() # Saving the file in string variable.\n",
    "\n",
    "#Displaying first 435 characters \n",
    "print(fullTexts[:435])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a85f19ae-addd-4504-89a0-008d7bd04447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kbr', 'said', 'friday', 'the', 'global', 'economic', 'downturn', 'so', 'far', 'has', 'had', 'little', 'effect', 'on', 'its', 'business', 'but', 'warned', 'some', 'projects', 'on', 'its', 'books', 'could', 'be', 'in', 'jeopardy', 'if', 'the', 'headwinds', 'persist', 'into', 'next', 'year', 'with', 'the', 'economic', 'outlook', 'remaining', 'uncertain', 'it', 'is', 'possible', 'that']\n"
     ]
    }
   ],
   "source": [
    "# Lets tokenize the words as a first task:\n",
    "import re\n",
    "# For the first step, lets start with breaking the words and converting to lowercase\n",
    "allRefinedWords = re.findall(r'\\b\\w+\\b', fullTexts.lower()) #I have used regex in order to get the words without the punctuation.\n",
    "\n",
    "#Lets check if it works or not\n",
    "print(allRefinedWords[:44])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe25f570-9f26-4cf2-9b5f-2eb79f239e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output bigrams pair is : \n",
      "First Word | Second Word \n",
      "kbr\t\tsaid\n",
      "said\t\tfriday\n",
      "friday\t\tthe\n",
      "the\t\tglobal\n"
     ]
    }
   ],
   "source": [
    "# Completed tokenizing the word.\n",
    "# Starting second task: Create two almost-duplicate files of words, off by one line, using tail:\n",
    "firstWords = allRefinedWords[:-1] # Except the last one\n",
    "secondWords = allRefinedWords[1:] # Except the first one\n",
    "\n",
    "#Lets check the output pairs.\n",
    "print(\"The output bigrams pair is : \\nFirst Word | Second Word \")\n",
    "for i in range(4):\n",
    "    print(firstWords[i]+\"\\t\\t\"+ secondWords[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6edc4c48-ccdf-4ace-9abf-821b27906bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THe created bigrams are:  [('kbr', 'said'), ('said', 'friday'), ('friday', 'the'), ('the', 'global'), ('global', 'economic'), ('economic', 'downturn'), ('downturn', 'so'), ('so', 'far'), ('far', 'has'), ('has', 'had'), ('had', 'little'), ('little', 'effect'), ('effect', 'on')]\n"
     ]
    }
   ],
   "source": [
    "# Doing the third task : Paste them together so as to get word(i) and word(i +1) on the same line.\n",
    "# Lets create bigrams\n",
    "createdBigram = list(zip(firstWords, secondWords))\n",
    "\n",
    "#Printing some of the outputs\n",
    "print(\"THe created bigrams are: \", createdBigram[:13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0d9224e-ae8a-462f-9552-16a167a9d8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 10 most common bigrams got as an output is:\n",
      "('of', 'the')  :  3154\n",
      "('in', 'the')  :  2758\n",
      "('to', 'the')  :  1196\n",
      "('on', 'the')  :  1159\n",
      "('for', 'the')  :  942\n",
      "('and', 'the')  :  859\n",
      "('in', 'a')  :  846\n",
      "('it', 's')  :  776\n",
      "('at', 'the')  :  773\n",
      "('to', 'be')  :  743\n"
     ]
    }
   ],
   "source": [
    "# Here I can see the output as I expected. Now, I am doing the last one which is: Provide the commands to find the 10 most common bigrams.â€¯\n",
    "from collections import Counter\n",
    "\n",
    "#Counting the occurance of all the created bigram\n",
    "allBigramCount = Counter(createdBigram)\n",
    "\n",
    "#Now, filtering the most 10 common bigrams\n",
    "commonBigramsFiltered = allBigramCount.most_common(10)\n",
    "\n",
    "#Displaying the result\n",
    "print(\"The top 10 most common bigrams got as an output is:\")\n",
    "for bigramFiltered, count in commonBigramsFiltered:\n",
    "    print(f\"{bigramFiltered}  :  {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb07faf-5b93-40bc-85ee-2e1f9a0a0ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is the final output of the assignment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
